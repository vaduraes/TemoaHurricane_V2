{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:673: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:683: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:689: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:695: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:699: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:703: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:711: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:717: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:721: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:725: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:732: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:741: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:749: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:757: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:765: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is '':\n",
      "c:\\Users\\Remote\\Desktop\\Projects\\TemoaHurricane_OEA\\TEMOA_GIT\\TemoaHurricane_V2\\TemoaStochastic\\WriteStochasticFiles\\../temoa_stochastic/temoa_model\\pformat_results.py:769: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if len(row_data) is 7:\n"
     ]
    },
    {
     "data": {
      "application/javascript": "if (typeof IPython !== 'undefined') { IPython.OutputArea.prototype._should_scroll = function(lines){ return false; }}",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.00] Initializing mpi-sppy\n"
     ]
    }
   ],
   "source": [
    "# python temoa_model/temoa_stochastic.py --config=temoa_model/config_sample (Cluster)\n",
    "# python temoa_model/temoa_stochastic.py --config=temoa_model/config     (desktop) \n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, \"../temoa_stochastic/data_processing/\")\n",
    "sys.path.insert(0, \"../temoa_stochastic/temoa_model\") #temoa model module\n",
    "import temoa_model\n",
    "import temoa_config  \n",
    "\n",
    "#mpi-sppy\n",
    "import mpisppy.phbase\n",
    "import mpisppy.opt.ph\n",
    "import mpisppy.opt.aph\n",
    "import mpisppy.scenario_tree as scenario_tree\n",
    "import pyomo.environ as pyo\n",
    "import mpisppy.utils.sputils as sputils\n",
    "import sqlite3\n",
    "\n",
    "#Delete contents of the folder with the input data for TEMOA created in the previous run\n",
    "def create_or_delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Contents of folder '{folder_path}' deleted successfully.\")\n",
    "    else:\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully.\")\n",
    "        \n",
    "#Block Some Prints from TEMOA, too much noise\n",
    "temp_stdout = None\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    global temp_stdout\n",
    "    temp_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    global temp_stdout\n",
    "    sys.stdout = temp_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of folder './Import2TemoaFiles/' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "PowerSystemFileName=\"NC_EnergySystem2023.sqlite\"\n",
    "PathPowerSystemData=\"./InputData/\"+PowerSystemFileName\n",
    "PercentageDamagePath=\"./InputData/PercentageHurricaneDamage.xlsx\"\n",
    "ProbabilityScenariosPath=\"./InputData/ProbabilityEachScenario.xlsx\"\n",
    "AverageNumberOfEventsPerScenario=\"./InputData/AverageNumberOfEventsPerScenario.xlsx\"\n",
    "\n",
    "PathWriteTemoaInputData=\"./Import2TemoaFiles/\"\n",
    "PathScenarioTree=PathWriteTemoaInputData+\"Scenarios/\"\n",
    "\n",
    "\n",
    "#Delete contents of the folder with the input data for TEMOA created in the previous run\n",
    "create_or_delete_folder(PathWriteTemoaInputData)\n",
    "shutil.copyfile(PathPowerSystemData, PathWriteTemoaInputData+PowerSystemFileName)#copy of .sqlite file\n",
    "\n",
    "df_percentage_damage = pd.read_excel(PercentageDamagePath)\n",
    "df_probability_scenarios = pd.read_excel(ProbabilityScenariosPath)\n",
    "df_num_events_scenario = pd.read_excel(AverageNumberOfEventsPerScenario)\n",
    "os.makedirs(PathScenarioTree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Scenario Tree Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a .dat file from the.sqlite file\n",
    "DatFilePath=PathScenarioTree+\"R_.dat\"#Root node\n",
    "\n",
    "class C_Options:\n",
    "  def __init__(self, myopic=False, mga_weight=False):\n",
    "    self.myopic = myopic\n",
    "    self.mga_weight = mga_weight\n",
    "\n",
    "options=C_Options()\n",
    "blockPrint()\n",
    "temoa_config.db_2_dat(PathPowerSystemData,DatFilePath,options)\n",
    "enablePrint()\n",
    "shutil.copyfile(PathPowerSystemData, PathPowerSystemData[:-7]+\".dat\")#copy of .sqlite file\n",
    "\n",
    "#Create a pyomo isntance of TEMOA\n",
    "TEMOA_Model=temoa_model.temoa_create_model()\n",
    "blockPrint()\n",
    "Instance = TEMOA_Model.create_instance( DatFilePath ) \n",
    "enablePrint()\n",
    "\n",
    "TimeStages = sorted( getattr(Instance, 'time_optimize').data() )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMOA_CAPREDUCTION_Keys= list(Instance.CapReduction.keys())\n",
    "# dir_CAPREDUCTION_Keys={ \"Regions\": np.array([i[0] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Periods\": np.array([i[1] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Tech\":    np.array([i[2] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Vintage\": np.array([i[3] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Key\":     TEMOA_CAPREDUCTION_Keys}\n",
    "\n",
    "#Since I represented all costs even if they are zero, I can use CostFixed to get valid indexed for capacity reduction\n",
    "con = sqlite3.connect(PathPowerSystemData)\n",
    "ValidIdxForCapReduction_sql = pd.read_sql_query(\"SELECT * FROM CostFixed\", con)\n",
    "con.close()\n",
    "\n",
    "\n",
    "\n",
    "dir_CAPREDUCTION_Keys={ \"Regions\": ValidIdxForCapReduction_sql[\"regions\"].values,\n",
    "                        \"Periods\": ValidIdxForCapReduction_sql[\"periods\"].values,\n",
    "                        \"Tech\":    ValidIdxForCapReduction_sql[\"tech\"].values,\n",
    "                        \"Vintage\": ValidIdxForCapReduction_sql[\"vintage\"].values}\n",
    "\n",
    "\n",
    "def WriteNodeData(NodeName, CapReductionNodeInfo, PathScenarioTree=PathScenarioTree, dir_CAPREDUCTION_Keys=dir_CAPREDUCTION_Keys):\n",
    "\n",
    "    NodeYear=CapReductionNodeInfo.columns[2]\n",
    "    PreviousNodeYear=CapReductionNodeInfo.columns[3]\n",
    "\n",
    "    LastYear=CapReductionNodeInfo.columns[-1]\n",
    "\n",
    "    TEMOA_Region=dir_CAPREDUCTION_Keys[\"Regions\"]\n",
    "    TEMOA_Period=dir_CAPREDUCTION_Keys[\"Periods\"]\n",
    "    TEMOA_Tech=dir_CAPREDUCTION_Keys[\"Tech\"]\n",
    "    TEMOA_Vintage=dir_CAPREDUCTION_Keys[\"Vintage\"]\n",
    "\n",
    "    file = open(PathScenarioTree+NodeName+\".dat\", \"w\")\n",
    "    Line1=\"param CapReduction:=\\n\"\n",
    "    file.write(Line1)\n",
    "\n",
    "    for row in CapReductionNodeInfo.iterrows():\n",
    "        region=row[1][\"regions\"]\n",
    "        tech=row[1][\"tech\"]\n",
    "\n",
    "\n",
    "        #look at all tech with vintage less than previous node year, those are affected by the cap reduction\n",
    "        IdxIn2Change=(TEMOA_Region==region)*(TEMOA_Tech==tech)*(TEMOA_Vintage<=PreviousNodeYear)*(TEMOA_Period==NodeYear)#All other elements must be equal to one which is the default value\n",
    "        #(TEMOA_Period==NodeYear): technology may have already retired at the period of the node\n",
    "\n",
    "        TEMOA_Region_tmp=TEMOA_Region[IdxIn2Change]\n",
    "        TEMOA_Period_tmp=TEMOA_Period[IdxIn2Change]\n",
    "        TEMOA_Tech_tmp=TEMOA_Tech[IdxIn2Change]\n",
    "        TEMOA_Vintage_tmp=TEMOA_Vintage[IdxIn2Change]\n",
    "        rate=np.ones(len(TEMOA_Region_tmp))\n",
    "\n",
    "        for v in np.unique(TEMOA_Vintage_tmp):\n",
    "\n",
    "            if v<=LastYear:\n",
    "                IdxIn=(TEMOA_Vintage_tmp<=LastYear)\n",
    "                rate[IdxIn]=row[1][LastYear]\n",
    "            else:\n",
    "                IdxIn=(TEMOA_Vintage_tmp==v)\n",
    "                rate[IdxIn]=row[1][v]\n",
    "            \n",
    "        Lines=[]\n",
    "        for i in range(len(TEMOA_Region_tmp)):\n",
    "            Line=TEMOA_Region_tmp[i] +\"   \"+ str(NodeYear)+\"   \"+TEMOA_Tech_tmp[i]+\"   \"+str(TEMOA_Vintage_tmp[i])+\"   \"+str(rate[i])+\"\\n\"\n",
    "            file.write(Line)\n",
    "\n",
    "    file.write(\";\")\n",
    "    file.close()\n",
    "    #print(f\"File {NodeName}.dat created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: 1 ----ok\n",
      "Stage: 2 ----ok\n",
      "Stage: 3 ----ok\n",
      "Stage: 4 ----ok\n",
      "Stage: 5 ----ok\n",
      "Stage: 6 ----ok\n"
     ]
    }
   ],
   "source": [
    "NodeStages=TimeStages\n",
    "NumStages=len(NodeStages)\n",
    "ScenariosEachStage=list(df_probability_scenarios.columns[1:])\n",
    "RootNodeName=\"R_\"\n",
    "\n",
    "LastStageNodesMapped=[RootNodeName]\n",
    "LastStageNodesMapped_tmp=[]\n",
    "CountTimeStages=1\n",
    "\n",
    "SetNodes=[]\n",
    "SetNodes.append(RootNodeName)\n",
    "Dic_ChildrenNodes={}\n",
    "\n",
    "Dic_NodeYear={}\n",
    "Dic_NodeYear[RootNodeName]=NodeStages[0]\n",
    "\n",
    "ConditionalProbability={}\n",
    "ConditionalProbability[RootNodeName]=1\n",
    "\n",
    "while CountTimeStages<NumStages:\n",
    "    print(\"Stage: %d ----ok\"%(CountTimeStages))\n",
    "    for LSNode in LastStageNodesMapped:\n",
    "        ListChildrenNodes=[]\n",
    "        for scenario in ScenariosEachStage:\n",
    "            \n",
    "            NodeName=LSNode+scenario+\"_\"\n",
    "            \n",
    "            LastStageNodesMapped_tmp.append(NodeName)\n",
    "            ScenariosNeeded=NodeName.split(\"_\")[1:-1]#Sequence of Nodes\n",
    "            ScenariosNeeded.reverse()\n",
    "\n",
    "            #Put together the information of the nodes needed to create the scenario\n",
    "            Vintages=NodeStages[0:CountTimeStages]#Vintage Intervals we need to be aware of\n",
    "            Vintages.reverse()\n",
    "\n",
    "            \n",
    "            #Contain information about capacity reduction for each technology and region Considering its vintage at the current node\n",
    "            #Which is associated with a CurrentTimeStage\n",
    "            CapReductionNodeInfo=df_percentage_damage[[\"regions\",\"tech\"]].copy() \n",
    "            CurrentTimeStage=NodeStages[CountTimeStages]\n",
    "            CapReductionNodeInfo[CurrentTimeStage]=1 #Tech deployed (vintage) at the node time stage is not affected by damages at of before the node\n",
    "            \n",
    "            #Mapping different tech vintages from the perspective of the current node\n",
    "            #What is the damage a tech with vintage (X) see at the current node?\n",
    "            for i in range(len(Vintages)):\n",
    "                Vintage=Vintages[i] #Remember vintages are reversed\n",
    "                s_tmp=ScenariosNeeded[0:i+1] #Scenarios associated with the vintage (are reversed)\n",
    "                \n",
    "                CapReductionNodeInfo[Vintage]=1 #Capacity reduction for technologies deployed before this specific vintage (will be updated)\n",
    "\n",
    "                count_runs=0\n",
    "                for s in s_tmp:\n",
    "                    year_tmp_scenario=Vintages[count_runs]#Year of the individual S$ scenario\n",
    "                    count_runs=count_runs+1\n",
    "                    \n",
    "                    AvgNumEventsInScenario=df_num_events_scenario.loc[df_num_events_scenario[\"t_periods\"]==year_tmp_scenario,s].values[0]# Depends on the length of the period\n",
    "                    P_DamageNodeInfo=df_percentage_damage[s]*AvgNumEventsInScenario\n",
    "                    \n",
    "                    if s==\"S0\":\n",
    "                        #For the case where we have S0 we need to adjust the damage to account for no damage events\n",
    "                        #The original S0 from excel assumes that at least one hazus recurrent event happens\n",
    "                        #New Damage = PDamage(H)*P(H)+ 0*(1-P(H))=PDamage(H)*P(H)\n",
    "                        P_Hazus=df_probability_scenarios.loc[df_probability_scenarios[\"t_periods\"]==year_tmp_scenario,s].values[0]\n",
    "                        P_DamageNodeInfo=P_DamageNodeInfo*P_Hazus #Will reduce the damage to take into account no hurricane may happen \n",
    "                    \n",
    "                    CapReductionNodeInfo[Vintage]=CapReductionNodeInfo[Vintage]*(1-P_DamageNodeInfo)\n",
    "\n",
    "            LastScenario=ScenariosNeeded[0]# Remember array is reversed\n",
    "            \n",
    "            if LastScenario!=\"S0\":\n",
    "                ConditionalProbability[NodeName]=round(df_probability_scenarios.at[len(ScenariosNeeded)-1,LastScenario],10)\n",
    "            else:\n",
    "                #The probabilities on excel consider that at least one hazus event happens\n",
    "                #we need to adjust the probabilities to account for the case where no hazus event happens\n",
    "                # P(S0)=1-P(S1)-P(S2)-P(S3)-P(S4),...-P(Sn)\n",
    "                ConditionalProbability[NodeName]=round(1-df_probability_scenarios.iloc[len(ScenariosNeeded)-1,2:].sum(),10)\n",
    "                \n",
    "            ListChildrenNodes.append(NodeName)\n",
    "            SetNodes.append(NodeName)\n",
    "            WriteNodeData(NodeName, CapReductionNodeInfo)\n",
    "            Dic_NodeYear[NodeName]=NodeStages[CountTimeStages]\n",
    "\n",
    "\n",
    "        Dic_ChildrenNodes[LSNode]=ListChildrenNodes\n",
    "\n",
    "    CountTimeStages=CountTimeStages+1        \n",
    "    LastStageNodesMapped=LastStageNodesMapped_tmp\n",
    "    LastStageNodesMapped_tmp=[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scenarios=[ '_'.join(s.split(\"_\")[1:-1]) for s in LastStageNodesMapped] #Create scenario names\n",
    "\n",
    "#Write satage name of each node\n",
    "Dic_NodeStage={}\n",
    "for iten in list(Dic_NodeYear.keys()):\n",
    "    Dic_NodeStage[iten]=\"s\"+str(Dic_NodeYear[iten])\n",
    "\n",
    "#Write ScenarioLeafNode\n",
    "ScenarioLeafNode={}\n",
    "for s in Scenarios:\n",
    "    ScenarioLeafNode[s]=RootNodeName+s+\"_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage Variables\n",
    "\n",
    "def StageVariablesList(Period,Instance=Instance):\n",
    "    stage_vars = list()\n",
    "\n",
    "    V_FlowOut_keys = [index for index in Instance.V_FlowOut.keys()\n",
    "                    if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_FlowOut[{},{},{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_FlowOut_keys )))\n",
    "\n",
    "\n",
    "    V_FlowIn_keys = [index for index in Instance.V_FlowIn.keys()\n",
    "                    if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_FlowIn[{},{},{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_FlowIn_keys )))\n",
    "\n",
    "\n",
    "    V_FlowOutAnnual_keys= [index for index in Instance.V_FlowOutAnnual.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_FlowOutAnnual[{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_FlowOutAnnual_keys )))\n",
    "\n",
    "\n",
    "    V_Flex_keys = [index for index in Instance.V_Flex.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_Flex[{},{},{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_Flex_keys )))\n",
    "\n",
    "\n",
    "    V_FlexAnnual_keys = [index for index in Instance.V_FlexAnnual.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_FlexAnnual[{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_FlexAnnual_keys )))\n",
    "\n",
    "\n",
    "    V_Curtailment_keys = [index for index in Instance.V_Curtailment.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_Curtailment[{},{},{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_Curtailment_keys )))\n",
    "\n",
    "\n",
    "    V_StorageLevel_keys = [index for index in Instance.V_StorageLevel.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_StorageLevel[{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_StorageLevel_keys )))\n",
    "\n",
    "\n",
    "    V_StorageInit_keys = [index for index in Instance.V_StorageInit.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_StorageInit[{},{},{},{},{},{}]'.format( *index )\n",
    "                for index in V_StorageInit_keys )))\n",
    "\n",
    "\n",
    "    V_Capacity_keys = [index for index in Instance.V_Capacity.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_Capacity[{},{},{}]'.format( *index )\n",
    "                for index in V_Capacity_keys )))\n",
    "\n",
    "\n",
    "    V_CapacityAvailableByPeriodAndTech_keys = [index for index in Instance.V_CapacityAvailableByPeriodAndTech.keys()\n",
    "                        if index[1] == Period]\n",
    "    stage_vars.extend(sorted(set('V_CapacityAvailableByPeriodAndTech[{},{},{}]'.format( *index )\n",
    "                for index in V_CapacityAvailableByPeriodAndTech_keys )))\n",
    "    return stage_vars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def WriteTree(NodeStages, PathScenarioTree=PathScenarioTree):\n",
    "file = open(PathScenarioTree+\"ScenarioStructure.dat\", \"w\")\n",
    "\n",
    "#Stages\n",
    "file.write(\"set  Stages  :=\\n\")\n",
    "for s in NodeStages:\n",
    "    Line=\"s\"+str(s)+\"\\n\"\n",
    "    file.write(Line)\n",
    "file.write(\";\\n\")\n",
    "\n",
    "#Scenarios\n",
    "file.write(\"set  Scenarios  :=\\n\")\n",
    "for s in Scenarios:\n",
    "    file.write(s+\"\\n\")\n",
    "file.write(\";\\n\")\n",
    "\n",
    "#Nodes\n",
    "file.write(\"set  Nodes  :=\\n\")\n",
    "for n in SetNodes:\n",
    "    file.write(n+\"\\n\")\n",
    "file.write(\";\\n\")\n",
    "\n",
    "#Children Nodes\n",
    "for MainNode in list(Dic_ChildrenNodes.keys()):\n",
    "    ChNodes=Dic_ChildrenNodes[MainNode]\n",
    "    file.write(\"set  Children[\"+MainNode+\"]  :=\\n\")\n",
    "    for n in ChNodes:\n",
    "        file.write(n+\"\\n\")\n",
    "    file.write(\";\\n\")\n",
    "\n",
    "#Node Stage\n",
    "file.write(\"param  NodeStage  :=\\n\")\n",
    "for n in list(Dic_NodeStage.keys()):\n",
    "    Line=n+\"   \"+Dic_NodeStage[n]+\"\\n\"\n",
    "    file.write(Line)\n",
    "file.write(\";\\n\")\n",
    "\n",
    "#ScenarioLeafNode\n",
    "file.write(\"param  ScenarioLeafNode  :=\\n\")\n",
    "for s in list(ScenarioLeafNode.keys()):\n",
    "    Line=s+\"   \"+ScenarioLeafNode[s]+\"\\n\"\n",
    "    file.write(Line)\n",
    "file.write(\";\\n\")\n",
    "\n",
    "#StageCost\n",
    "file.write(\"param  StageCost  :=\\n\")\n",
    "for sy in NodeStages:\n",
    "    Line=\"s\"+str(sy)+\"   \"+\"StochasticPointCost[\"+str(sy)+\"]\\n\"\n",
    "    file.write(Line)\n",
    "\n",
    "file.write(\";\\n\")\n",
    "\n",
    "#ConditionalProbability\n",
    "file.write(\"param  ConditionalProbability  :=\\n\")\n",
    "for n in list(ConditionalProbability.keys()):\n",
    "    Line=n+\"   \"+str(ConditionalProbability[n])+\"\\n\"\n",
    "    file.write(Line)\n",
    "\n",
    "file.write(\";\\n\")\n",
    "\n",
    "#Stage Variables\n",
    "for period in NodeStages:\n",
    "    stage_vars=StageVariablesList(Period=period)\n",
    "\n",
    "    file.write(\"set  StageVariables[s\"+str(period)+\"]\"+\"  :=\\n\")\n",
    "    for v in stage_vars:\n",
    "        file.write(v+\"\\n\")\n",
    "    file.write(\";\\n\")\n",
    "\n",
    "#ScenarioBasedData\n",
    "file.write(\"param  ScenarioBasedData  :=  False ;\")\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temoa_OEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
